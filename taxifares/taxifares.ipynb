{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reworking of this:\n",
    "\n",
    "[http://localhost:8888/notebooks/training-data-analyst/courses/machine_learning/deepdive/03_tensorflow/e_cloudmle.ipynb#Deploy-model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'kouzoh-p-michal'   \n",
    "BUCKET = 'ml-training-kouzoh-p-michal-appspot-com' \n",
    "REGION = 'us-central1' \n",
    "\n",
    "MODEL_NAME = 'taxifare'\n",
    "MODEL_VERSION = 'v1'\n",
    "TRAINING_DIR = './data/taxi_trained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8' \n",
    "os.environ['CLOUDSDK_PYTHON'] = 'python2'\n",
    "os.environ['MODEL_NAME'] = MODEL_NAME\n",
    "os.environ['MODEL_VERSION'] = MODEL_VERSION\n",
    "os.environ['TRAINING_DIR'] = TRAINING_DIR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data check\n",
    "Data is prepared as CSVs and uploaded to the bucket in a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#gsutil cp gs://$BUCKET/taxifare/ch4/taxi_preproc/test.csv-00000-of-00001 ./data/test.csv\n",
    "#gsutil cp gs://$BUCKET/taxifare/ch4/taxi_preproc/train.csv-00000-of-00001 ./data/train.csv\n",
    "#gsutil cp gs://$BUCKET/taxifare/ch4/taxi_preproc/valid.csv-00000-of-00001 ./data/valid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove trained model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#rm -rf $TRAINING_DIR/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f703ea6b290>, '_model_dir': './data/taxi_trained', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/var/dev/ml-experiments/taxifares/taxifare/trainer/task.py\", line 108, in <module>\n",
      "    model.train_and_evaluate(arguments)\n",
      "  File \"/var/dev/ml-experiments/taxifares/taxifare/trainer/model.py\", line 106, in train_and_evaluate\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 610, in run\n",
      "    return self.run_local()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 711, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1207, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1237, in _train_model_default\n",
      "    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1195, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 656, in _model_fn\n",
      "    shared_state_manager=shared_state_manager)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 300, in _dnn_model_fn\n",
      "    logits = logit_fn(features=features, mode=mode)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 109, in dnn_logit_fn\n",
      "    return dnn_model(features, mode)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 757, in __call__\n",
      "    outputs = self.call(inputs, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 204, in call\n",
      "    net = self._input_layer(features)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 333, in __call__\n",
      "    from_template=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/template.py\", line 368, in __call__\n",
      "    return self._call_func(args, kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/template.py\", line 311, in _call_func\n",
      "    result = self._func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 222, in _internal_input_layer\n",
      "    return _get_logits()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 201, in _get_logits\n",
      "    trainable=trainable)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 2500, in _get_dense_tensor\n",
      "    return inputs.get(self)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 2289, in get\n",
      "    transformed = column._transform_feature(self)  # pylint: disable=protected-access\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 2468, in _transform_feature\n",
      "    input_tensor = inputs.get(self.key)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 2281, in get\n",
      "    raise ValueError('Feature {} is not in features dictionary.'.format(key))\n",
      "ValueError: Feature passengers is not in features dictionary.\n",
      "\n",
      "originally defined at:\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 108, in dnn_logit_fn\n",
      "    name='dnn')\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/canned/dnn.py\", line 143, in __init__\n",
      "    create_scope_now=False)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/feature_column/feature_column.py\", line 323, in __init__\n",
      "    self._name, _internal_input_layer, create_scope_now_=create_scope_now)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/template.py\", line 154, in make_template\n",
      "    **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Setup python so it sees the task module which controls the model.py\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/${MODEL_NAME}\n",
    "python -m trainer.task \\\n",
    "   --train_data_paths=./data/train.csv \\\n",
    "   --eval_data_paths=./data/valid.csv  \\\n",
    "   --output_dir=${TRAINING_DIR} \\\n",
    "   --train_steps=1000 --job-dir=./data/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model locally using gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {}, u'job': {u'args': [u'--train_data_paths=/var/dev/ml-experiments/taxifares/taxi-train.csv', u'--eval_data_paths=/var/dev/ml-experiments/taxifares/taxi-valid.csv', u'--train_steps=1000', u'--output_dir=/var/dev/ml-experiments/taxifares/./data/taxi_trained'], u'job_name': u'trainer.task'}, u'task': {}}\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f653776f990>, '_model_dir': '/var/dev/ml-experiments/taxifares/./data/taxi_trained', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use Cloud Machine Learning Engine to train the model in local file system\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/${MODEL_NAME}/trainer \\\n",
    "   -- \\\n",
    "   --train_data_paths=${PWD}/taxi-train.csv \\\n",
    "   --eval_data_paths=${PWD}/taxi-valid.csv  \\\n",
    "   --train_steps=1000 \\\n",
    "   --output_dir=${PWD}/${TRAINING_DIR} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit trainig job to cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-training-kouzoh-p-michal-appspot-com/taxifare/ch4/trained us-central1 taxifare_190215_152520\n",
      "jobId: taxifare_190215_152520\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [taxifare_190215_152520] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe taxifare_190215_152520\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs taxifare_190215_152520\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/taxifare/ch4/trained\n",
    "JOBNAME=${MODEL_NAME}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "# Clear the Cloud Storage Bucket used for the training job\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/${MODEL_NAME}/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --train_data_paths=\"gs://${BUCKET}/taxifare/ch4/taxi_preproc/train*\" \\\n",
    "   --eval_data_paths=\"gs://${BUCKET}/taxifare/ch4/taxi_preproc/valid*\"  \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what's in the directory where cloud training outputs the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-training-kouzoh-p-michal-appspot-com/taxifare/ch4/trained/export/exporter/\n",
      "gs://ml-training-kouzoh-p-michal-appspot-com/taxifare/ch4/trained/export/exporter/1550244453/\n",
      "gs://ml-training-kouzoh-p-michal-appspot-com/taxifare/ch4/trained/export/exporter/1550244989/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/taxifare/ch4/trained/export/exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy model - this just creates a model without any content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/kouzoh-p-michal/models/taxifare].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Deploy trained version to the model we created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_LOCATION = gs://ml-training-kouzoh-p-michal-appspot-com/taxifare/ch4/trained/export/exporter/1550244989/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......\n",
      "..............................................................................................................................................................................................................................................................................................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/taxifare/ch4/trained/export/exporter | tail -1)\n",
    "\n",
    "echo \"MODEL_LOCATION = ${MODEL_LOCATION}\"\n",
    "\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
